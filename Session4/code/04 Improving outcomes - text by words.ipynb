{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Barcode</th>\n",
       "      <th>UnitRRP</th>\n",
       "      <th>CategoryID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.260000e+02</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>526.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.771880e+12</td>\n",
       "      <td>416.119772</td>\n",
       "      <td>441.404943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.941241e+09</td>\n",
       "      <td>173.972146</td>\n",
       "      <td>197.596350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.770002e+12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.770886e+12</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>528.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.771081e+12</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>529.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.771744e+12</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>531.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.790951e+12</td>\n",
       "      <td>1299.000000</td>\n",
       "      <td>532.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Barcode      UnitRRP  CategoryID\n",
       "count  5.260000e+02   526.000000  526.000000\n",
       "mean   9.771880e+12   416.119772  441.404943\n",
       "std    2.941241e+09   173.972146  197.596350\n",
       "min    9.770002e+12     0.000000    1.000000\n",
       "25%    9.770886e+12   330.000000  528.000000\n",
       "50%    9.771081e+12   395.000000  529.000000\n",
       "75%    9.771744e+12   475.000000  531.000000\n",
       "max    9.790951e+12  1299.000000  532.000000"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Data\n",
    "training_raw = pd.read_table(\"../data/training_data.dat\")\n",
    "df_training = pd.DataFrame(training_raw)\n",
    "df_training.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Barcode</th>\n",
       "      <th>UnitRRP</th>\n",
       "      <th>CategoryID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.910000e+02</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.771487e+12</td>\n",
       "      <td>399.528796</td>\n",
       "      <td>410.816754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.319726e+09</td>\n",
       "      <td>185.199147</td>\n",
       "      <td>221.482429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.770004e+12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.770140e+12</td>\n",
       "      <td>304.500000</td>\n",
       "      <td>528.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.771350e+12</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>529.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.772042e+12</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>530.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.781910e+12</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>532.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Barcode      UnitRRP  CategoryID\n",
       "count  1.910000e+02   191.000000  191.000000\n",
       "mean   9.771487e+12   399.528796  410.816754\n",
       "std    2.319726e+09   185.199147  221.482429\n",
       "min    9.770004e+12     0.000000    1.000000\n",
       "25%    9.770140e+12   304.500000  528.000000\n",
       "50%    9.771350e+12   390.000000  529.000000\n",
       "75%    9.772042e+12   440.000000  530.000000\n",
       "max    9.781910e+12  1200.000000  532.000000"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test Data\n",
    "test_raw = pd.read_table(\"../data/test_data.dat\")\n",
    "df_test = pd.DataFrame(test_raw)\n",
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# target names\n",
    "target_categories = ['Unclassified','Art','Aviation','Boating','Camping /Walking /Climbing','Collecting']\n",
    "target_values = ['1','528','529','530','531','532']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9771471058036,           340],\n",
       "       [9770300169189,           399],\n",
       "       [9781909786417,           795]], dtype=int64)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features\n",
    "feature_names_integers = ['Barcode','UnitRRP']\n",
    "training_data_integers = df_training[feature_names_integers].values\n",
    "training_data_integers[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Todays Pilot\n",
       "1               Pilot\n",
       "2    Classic Airliner\n",
       "Name: Description, dtype: object"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training['Description'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(526, 305)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rather than Vectorizing the string as a whole do each word\n",
    "count_vect = CountVectorizer()\n",
    "count_vect.fit(df_training['Description'])\n",
    "training_data_description_vect_matrix = count_vect.transform(df_training['Description'])\n",
    "training_data_description_vect_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_description_vect_matrix.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<526x305 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 1081 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_description_vect_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So we work with the vectorized text along side the barcode and price, convert it to an array\n",
    "training_data_description_vect = training_data_description_vect_matrix.toarray()\n",
    "training_data_description_vect[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description: \"Todays Pilot\" - \"todays\" word number: 275 \"pilot\" word number: 216\n"
     ]
    }
   ],
   "source": [
    "print('Description: \"{}\" - \"todays\" word number: {} \"pilot\" word number: {}').format(\n",
    "    df_training['Description'][0],count_vect.vocabulary_.get(u'todays'),count_vect.vocabulary_.get(u'pilot'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9771471058036,           340,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             1,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             1,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0], dtype=int64)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using numpy's hstack append the vectorized text to the barcode and price\n",
    "training_data_combined = np.hstack((training_data_integers,training_data_description_vect))\n",
    "training_data_combined[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=511, splitter='best')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model = DecisionTreeClassifier(random_state=511)\n",
    "target = df_training[\"CategoryID\"].values\n",
    "model.fit(training_data_combined, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9770306563172,           370,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             1,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             1,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0,             0,\n",
       "                   0,             0,             0], dtype=int64)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do all this again for the test data\n",
    "test_data_integers = df_test[feature_names_integers].values\n",
    "test_data_description_vect_matrix = count_vect.transform(df_test['Description'])\n",
    "test_data_description_vect = test_data_description_vect_matrix.toarray()\n",
    "test_data_combined = np.hstack((test_data_integers,test_data_description_vect))\n",
    "test_data_combined[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = model.predict(test_data_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expected = df_test[\"CategoryID\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            precision    recall  f1-score   support\n",
      "\n",
      "              Unclassified       0.55      0.14      0.22        43\n",
      "                       Art       0.29      0.60      0.39        20\n",
      "                  Aviation       0.73      0.56      0.63        54\n",
      "                   Boating       0.51      0.75      0.61        28\n",
      "Camping /Walking /Climbing       0.41      0.73      0.52        15\n",
      "                Collecting       0.77      0.74      0.75        31\n",
      "\n",
      "               avg / total       0.59      0.54      0.52       191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(expected, predicted,    target_names=target_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6 16  4 12  5  0]\n",
      " [ 1 12  6  1  0  0]\n",
      " [ 0 10 30  4  9  1]\n",
      " [ 2  0  1 21  0  4]\n",
      " [ 0  1  0  1 11  2]\n",
      " [ 2  2  0  2  2 23]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53926701570680624"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(expected, predicted, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So an increase from 46%/47% to 54%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop words\n",
    "\n",
    "As we sure in the text processing session some words just add noise to the data set.\n",
    "\n",
    "So would adding the english stop words help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6 16  4 12  5  0]\n",
      " [ 1 12  6  1  0  0]\n",
      " [ 0 10 30  4  9  1]\n",
      " [ 2  0  1 21  0  4]\n",
      " [ 0  1  0  1 11  2]\n",
      " [ 2  2  0  2  2 23]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.53403141361256545"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect_stop = CountVectorizer(stop_words='english')\n",
    "count_vect_stop.fit(df_training['Description'])\n",
    "training_data_stop_description_vect_matrix = count_vect_stop.transform(df_training['Description'])\n",
    "training_data_stop_description_vect = training_data_stop_description_vect_matrix.toarray()\n",
    "training_data_stop_combined = np.hstack((training_data_integers,training_data_stop_description_vect))\n",
    "model = DecisionTreeClassifier(random_state=511)\n",
    "model.fit(training_data_stop_combined, target)\n",
    "test_data_stop_integers = df_test[feature_names_integers].values\n",
    "test_data_stop_description_vect_matrix = count_vect_stop.transform(df_test['Description'])\n",
    "test_data_stop_description_vect = test_data_stop_description_vect_matrix.toarray()\n",
    "test_data_stop_combined = np.hstack((test_data_stop_integers,test_data_stop_description_vect))\n",
    "predicted_stop = model.predict(test_data_stop_combined)\n",
    "print(metrics.confusion_matrix(expected, predicted))\n",
    "metrics.accuracy_score(expected, predicted_stop, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'a',\n",
       "           'about',\n",
       "           'above',\n",
       "           'across',\n",
       "           'after',\n",
       "           'afterwards',\n",
       "           'again',\n",
       "           'against',\n",
       "           'all',\n",
       "           'almost',\n",
       "           'alone',\n",
       "           'along',\n",
       "           'already',\n",
       "           'also',\n",
       "           'although',\n",
       "           'always',\n",
       "           'am',\n",
       "           'among',\n",
       "           'amongst',\n",
       "           'amoungst',\n",
       "           'amount',\n",
       "           'an',\n",
       "           'and',\n",
       "           'another',\n",
       "           'any',\n",
       "           'anyhow',\n",
       "           'anyone',\n",
       "           'anything',\n",
       "           'anyway',\n",
       "           'anywhere',\n",
       "           'are',\n",
       "           'around',\n",
       "           'as',\n",
       "           'at',\n",
       "           'back',\n",
       "           'be',\n",
       "           'became',\n",
       "           'because',\n",
       "           'become',\n",
       "           'becomes',\n",
       "           'becoming',\n",
       "           'been',\n",
       "           'before',\n",
       "           'beforehand',\n",
       "           'behind',\n",
       "           'being',\n",
       "           'below',\n",
       "           'beside',\n",
       "           'besides',\n",
       "           'between',\n",
       "           'beyond',\n",
       "           'bill',\n",
       "           'both',\n",
       "           'bottom',\n",
       "           'but',\n",
       "           'by',\n",
       "           'call',\n",
       "           'can',\n",
       "           'cannot',\n",
       "           'cant',\n",
       "           'co',\n",
       "           'con',\n",
       "           'could',\n",
       "           'couldnt',\n",
       "           'cry',\n",
       "           'de',\n",
       "           'describe',\n",
       "           'detail',\n",
       "           'do',\n",
       "           'done',\n",
       "           'down',\n",
       "           'due',\n",
       "           'during',\n",
       "           'each',\n",
       "           'eg',\n",
       "           'eight',\n",
       "           'either',\n",
       "           'eleven',\n",
       "           'else',\n",
       "           'elsewhere',\n",
       "           'empty',\n",
       "           'enough',\n",
       "           'etc',\n",
       "           'even',\n",
       "           'ever',\n",
       "           'every',\n",
       "           'everyone',\n",
       "           'everything',\n",
       "           'everywhere',\n",
       "           'except',\n",
       "           'few',\n",
       "           'fifteen',\n",
       "           'fify',\n",
       "           'fill',\n",
       "           'find',\n",
       "           'fire',\n",
       "           'first',\n",
       "           'five',\n",
       "           'for',\n",
       "           'former',\n",
       "           'formerly',\n",
       "           'forty',\n",
       "           'found',\n",
       "           'four',\n",
       "           'from',\n",
       "           'front',\n",
       "           'full',\n",
       "           'further',\n",
       "           'get',\n",
       "           'give',\n",
       "           'go',\n",
       "           'had',\n",
       "           'has',\n",
       "           'hasnt',\n",
       "           'have',\n",
       "           'he',\n",
       "           'hence',\n",
       "           'her',\n",
       "           'here',\n",
       "           'hereafter',\n",
       "           'hereby',\n",
       "           'herein',\n",
       "           'hereupon',\n",
       "           'hers',\n",
       "           'herself',\n",
       "           'him',\n",
       "           'himself',\n",
       "           'his',\n",
       "           'how',\n",
       "           'however',\n",
       "           'hundred',\n",
       "           'i',\n",
       "           'ie',\n",
       "           'if',\n",
       "           'in',\n",
       "           'inc',\n",
       "           'indeed',\n",
       "           'interest',\n",
       "           'into',\n",
       "           'is',\n",
       "           'it',\n",
       "           'its',\n",
       "           'itself',\n",
       "           'keep',\n",
       "           'last',\n",
       "           'latter',\n",
       "           'latterly',\n",
       "           'least',\n",
       "           'less',\n",
       "           'ltd',\n",
       "           'made',\n",
       "           'many',\n",
       "           'may',\n",
       "           'me',\n",
       "           'meanwhile',\n",
       "           'might',\n",
       "           'mill',\n",
       "           'mine',\n",
       "           'more',\n",
       "           'moreover',\n",
       "           'most',\n",
       "           'mostly',\n",
       "           'move',\n",
       "           'much',\n",
       "           'must',\n",
       "           'my',\n",
       "           'myself',\n",
       "           'name',\n",
       "           'namely',\n",
       "           'neither',\n",
       "           'never',\n",
       "           'nevertheless',\n",
       "           'next',\n",
       "           'nine',\n",
       "           'no',\n",
       "           'nobody',\n",
       "           'none',\n",
       "           'noone',\n",
       "           'nor',\n",
       "           'not',\n",
       "           'nothing',\n",
       "           'now',\n",
       "           'nowhere',\n",
       "           'of',\n",
       "           'off',\n",
       "           'often',\n",
       "           'on',\n",
       "           'once',\n",
       "           'one',\n",
       "           'only',\n",
       "           'onto',\n",
       "           'or',\n",
       "           'other',\n",
       "           'others',\n",
       "           'otherwise',\n",
       "           'our',\n",
       "           'ours',\n",
       "           'ourselves',\n",
       "           'out',\n",
       "           'over',\n",
       "           'own',\n",
       "           'part',\n",
       "           'per',\n",
       "           'perhaps',\n",
       "           'please',\n",
       "           'put',\n",
       "           'rather',\n",
       "           're',\n",
       "           'same',\n",
       "           'see',\n",
       "           'seem',\n",
       "           'seemed',\n",
       "           'seeming',\n",
       "           'seems',\n",
       "           'serious',\n",
       "           'several',\n",
       "           'she',\n",
       "           'should',\n",
       "           'show',\n",
       "           'side',\n",
       "           'since',\n",
       "           'sincere',\n",
       "           'six',\n",
       "           'sixty',\n",
       "           'so',\n",
       "           'some',\n",
       "           'somehow',\n",
       "           'someone',\n",
       "           'something',\n",
       "           'sometime',\n",
       "           'sometimes',\n",
       "           'somewhere',\n",
       "           'still',\n",
       "           'such',\n",
       "           'system',\n",
       "           'take',\n",
       "           'ten',\n",
       "           'than',\n",
       "           'that',\n",
       "           'the',\n",
       "           'their',\n",
       "           'them',\n",
       "           'themselves',\n",
       "           'then',\n",
       "           'thence',\n",
       "           'there',\n",
       "           'thereafter',\n",
       "           'thereby',\n",
       "           'therefore',\n",
       "           'therein',\n",
       "           'thereupon',\n",
       "           'these',\n",
       "           'they',\n",
       "           'thick',\n",
       "           'thin',\n",
       "           'third',\n",
       "           'this',\n",
       "           'those',\n",
       "           'though',\n",
       "           'three',\n",
       "           'through',\n",
       "           'throughout',\n",
       "           'thru',\n",
       "           'thus',\n",
       "           'to',\n",
       "           'together',\n",
       "           'too',\n",
       "           'top',\n",
       "           'toward',\n",
       "           'towards',\n",
       "           'twelve',\n",
       "           'twenty',\n",
       "           'two',\n",
       "           'un',\n",
       "           'under',\n",
       "           'until',\n",
       "           'up',\n",
       "           'upon',\n",
       "           'us',\n",
       "           'very',\n",
       "           'via',\n",
       "           'was',\n",
       "           'we',\n",
       "           'well',\n",
       "           'were',\n",
       "           'what',\n",
       "           'whatever',\n",
       "           'when',\n",
       "           'whence',\n",
       "           'whenever',\n",
       "           'where',\n",
       "           'whereafter',\n",
       "           'whereas',\n",
       "           'whereby',\n",
       "           'wherein',\n",
       "           'whereupon',\n",
       "           'wherever',\n",
       "           'whether',\n",
       "           'which',\n",
       "           'while',\n",
       "           'whither',\n",
       "           'who',\n",
       "           'whoever',\n",
       "           'whole',\n",
       "           'whom',\n",
       "           'whose',\n",
       "           'why',\n",
       "           'will',\n",
       "           'with',\n",
       "           'within',\n",
       "           'without',\n",
       "           'would',\n",
       "           'yet',\n",
       "           'you',\n",
       "           'your',\n",
       "           'yours',\n",
       "           'yourself',\n",
       "           'yourselves'})"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect_stop.get_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6 16  4 12  5  0]\n",
      " [ 1 12  6  1  0  0]\n",
      " [ 0 10 30  4  9  1]\n",
      " [ 2  0  1 21  0  4]\n",
      " [ 0  1  0  1 11  2]\n",
      " [ 2  2  0  2  2 23]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.52356020942408377"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect_stop = CountVectorizer(stop_words=['the'])\n",
    "count_vect_stop.fit(df_training['Description'])\n",
    "training_data_stop_description_vect_matrix = count_vect_stop.transform(df_training['Description'])\n",
    "training_data_stop_description_vect = training_data_stop_description_vect_matrix.toarray()\n",
    "training_data_stop_combined = np.hstack((training_data_integers,training_data_stop_description_vect))\n",
    "model = DecisionTreeClassifier(random_state=511)\n",
    "model.fit(training_data_stop_combined, target)\n",
    "test_data_stop_integers = df_test[feature_names_integers].values\n",
    "test_data_stop_description_vect_matrix = count_vect_stop.transform(df_test['Description'])\n",
    "test_data_stop_description_vect = test_data_stop_description_vect_matrix.toarray()\n",
    "test_data_stop_combined = np.hstack((test_data_stop_integers,test_data_stop_description_vect))\n",
    "predicted_stop = model.predict(test_data_stop_combined)\n",
    "print(metrics.confusion_matrix(expected, predicted))\n",
    "metrics.accuracy_score(expected, predicted_stop, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics.accuracy_score(expected, predicted_stop, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
